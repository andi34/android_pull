From 2c809af206b4c74f002ba07ba85559f859de4fb2 Mon Sep 17 00:00:00 2001
From: Vasyl Yushchyshen <vasyl.yushchyshen@ti.com>
Date: Wed, 18 Feb 2015 09:25:28 -0800
Subject: [PATCH 073/102] GPU: ION: OMAP: Add the map/unmap dma callbacks
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

New ION API require the map/unmap heap callback should be present.

Change-Id: I6b0de2ffa7f80e0fbba94b11986755a36ae55d9e
Signed-off-by: Vasyl Yushchyshen <vasyl.yushchyshen@globallogic.com>
Signed-off-by: D. Andrei Măceș <dmaces@nd.edu>
---
 drivers/gpu/ion/omap/omap_tiler_heap.c | 105 ++++++++++++++++++++++++++++++++-
 include/linux/omap_ion.h               |   8 +++
 2 files changed, 111 insertions(+), 2 deletions(-)

diff --git a/drivers/gpu/ion/omap/omap_tiler_heap.c b/drivers/gpu/ion/omap/omap_tiler_heap.c
index b25f07e..2187815 100644
--- a/drivers/gpu/ion/omap/omap_tiler_heap.c
+++ b/drivers/gpu/ion/omap/omap_tiler_heap.c
@@ -58,7 +58,7 @@ static int omap_tiler_heap_allocate(struct ion_heap *heap,
 				    unsigned long size, unsigned long align,
 				    unsigned long flags)
 {
-	if (size == 0)
+	if (buffer->flags & OMAP_ION_FLAG_NO_ALLOC_TILER_HEAP)
 		return 0;
 
 	pr_err("%s: This should never be called directly -- use the "
@@ -161,12 +161,58 @@ static void omap_tiler_free_dynamicpages(struct omap_tiler_info *info)
 	return;
 }
 
+static struct sg_table *omap_tiler_map_dma(struct omap_tiler_info *info,
+						struct ion_buffer *buffer)
+{
+	struct sg_table *table;
+	int ret, i;
+
+	if (buffer->sg_table) {
+		table = buffer->sg_table;
+		sg_free_table(table);
+	}
+	else {
+		table = kzalloc(sizeof(struct sg_table), GFP_KERNEL);
+		if (!table)
+			return ERR_PTR(-ENOMEM);
+	}
+
+	ret = sg_alloc_table(table, (info->lump ? 1 : info->n_tiler_pages),
+			GFP_KERNEL);
+	if (ret) {
+		kfree(table);
+		buffer->sg_table = NULL;
+		return ERR_PTR(ret);
+	}
+
+	if (info->lump) {
+		sg_set_page(table->sgl, virt_to_page(info->tiler_addrs[0]),
+			info->n_tiler_pages * PAGE_SIZE, 0);
+		return table;
+	}
+
+	for (i = 0; i < info->n_tiler_pages; i++) {
+		sg_set_page(table->sgl, virt_to_page(info->tiler_addrs[i]),
+			PAGE_SIZE, 0);
+	}
+	return table;
+}
+
+static void omap_tiler_unmap_dma(struct ion_buffer *buffer)
+{
+	if (buffer->sg_table == NULL)
+		return;
+	sg_free_table(buffer->sg_table);
+	kfree(buffer->sg_table);
+}
+
 int omap_tiler_alloc(struct ion_heap *heap,
 		     struct ion_client *client,
 		     struct omap_ion_tiler_alloc_data *data)
 {
 	struct ion_handle *handle;
 	struct ion_buffer *buffer;
+	struct sg_table *sg_table;
 	struct omap_tiler_info *info = NULL;
 	u32 n_phys_pages;
 	u32 n_tiler_pages;
@@ -255,7 +301,11 @@ int omap_tiler_alloc(struct ion_heap *heap,
 	data->stride = tiler_block_vstride(info->tiler_handle);
 
 	/* create an ion handle  for the allocation */
-	handle = ion_alloc(client, 0, 0, 1 << heap->id);
+
+	/* This hack is to avoid the call itself from ion_alloc()
+		when the buffer and handle are created */
+	handle = ion_alloc(client, PAGE_ALIGN(1), 0, 1 << OMAP_ION_HEAP_TILER,
+		heap->flags | OMAP_ION_FLAG_NO_ALLOC_TILER_HEAP);
 	if (IS_ERR_OR_NULL(handle)) {
 		ret = PTR_ERR(handle);
 		pr_err("%s: failure to allocate handle to manage tiler"
@@ -267,6 +317,10 @@ int omap_tiler_alloc(struct ion_heap *heap,
 	buffer->heap = heap;	/* clarify tiler heap */
 	buffer->size = v_size;
 	buffer->priv_virt = info;
+	sg_table = omap_tiler_map_dma(info, buffer);
+	if (IS_ERR(sg_table))
+		goto err;
+	buffer->sg_table = sg_table;
 	data->handle = handle;
 	data->offset = (size_t)(info->tiler_start & ~PAGE_MASK);
 
@@ -299,6 +353,7 @@ void omap_tiler_heap_free(struct ion_buffer *buffer)
 {
 	struct omap_tiler_info *info = buffer->priv_virt;
 
+	omap_tiler_unmap_dma(buffer);
 	tiler_unpin_block(info->tiler_handle);
 	tiler_free_block_area(info->tiler_handle);
 
@@ -324,6 +379,50 @@ static int omap_tiler_phys(struct ion_heap *heap,
 	return 0;
 }
 
+static struct sg_table *omap_tiler_map_dma_empty(
+					struct ion_buffer *buffer)
+{
+	struct sg_table *table;
+	int ret;
+
+	table = kzalloc(sizeof(struct sg_table), GFP_KERNEL);
+	if (!table)
+		return ERR_PTR(-ENOMEM);
+
+	ret = sg_alloc_table(table, 1, GFP_KERNEL);
+	if (ret) {
+		kfree(table);
+		return ERR_PTR(ret);
+	}
+
+	sg_set_page(table->sgl, virt_to_page(buffer->priv_virt), 1, 0);
+	return table;
+}
+
+struct sg_table *omap_tiler_heap_map_dma(struct ion_heap *heap,
+						struct ion_buffer *buffer)
+{
+	/*
+	* In case if called from omap_tiler_alloc() filling sgtable by fake table since
+	* we don't have omap_tiler_alloc_info which is required for proper sgtable
+	* allocation.
+	* This table will filled properly later by omap_tiler_alloc() itself since
+	* it has tiler allocation information.
+	*/
+	if (buffer->flags & OMAP_ION_FLAG_NO_ALLOC_TILER_HEAP) {
+		buffer->flags &= ~OMAP_ION_FLAG_NO_ALLOC_TILER_HEAP;
+		return omap_tiler_map_dma_empty(buffer);
+	}
+	if (buffer->sg_table == NULL)
+		return ERR_PTR(-EFAULT);
+	return buffer->sg_table;
+}
+
+void omap_tiler_heap_unmap_dma(struct ion_heap *heap,
+				      struct ion_buffer *buffer)
+{
+}
+
 int omap_tiler_pages(struct ion_client *client, struct ion_handle *handle,
 		     int *n, u32 **tiler_addrs)
 {
@@ -377,6 +476,8 @@ static struct ion_heap_ops omap_tiler_ops = {
 	.allocate = omap_tiler_heap_allocate,
 	.free = omap_tiler_heap_free,
 	.phys = omap_tiler_phys,
+	.map_dma = omap_tiler_heap_map_dma,
+	.unmap_dma = omap_tiler_heap_unmap_dma,
 	.map_user = omap_tiler_heap_map_user,
 };
 
diff --git a/include/linux/omap_ion.h b/include/linux/omap_ion.h
index a13a6e7..1ba4a7c 100644
--- a/include/linux/omap_ion.h
+++ b/include/linux/omap_ion.h
@@ -73,6 +73,14 @@ enum {
 
 #define OMAP_ION_HEAP_TILER_MASK (1 << OMAP_ION_HEAP_TYPE_TILER)
 
+/**
+ * allocation flags - the lower 16 bits are used by core ion, the upper 16
+ * bits are reserved for use by the heaps themselves.
+ */
+
+/*use this flag to distinguish either omap_tiler_alloc() is calling from ION core or OMAP IOCTL */
+#define OMAP_ION_FLAG_NO_ALLOC_TILER_HEAP	(1<<16)
+
 enum {
 	OMAP_ION_TILER_ALLOC,
 };
-- 
2.7.4

